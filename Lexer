import re

# Tokenize Vishvakrut code
def lexer(code):
    tokens = []
    
    # Define token patterns
    token_specification = [
        ('COMMENT',   r'#.*'),          # Comments
        ('NUMBER',    r'\d+'),          # Numbers
        ('ASSIGN',    r'='),            # Assignment operator
        ('VAR',       r'[a-zA-Z_][a-zA-Z0-9_]*'),  # Variables & function names
        ('FUNCTION',  r'[a-zA-Z]+\('), # Function names like 'show(' etc.
        ('STRING',    r"'.*?'|\".*?\""),  # Capture both single and double-quoted strings
        ('LPAREN',    r'\('),           # Left parenthesis
        ('RPAREN',    r'\)'),           # Right parenthesis
        ('OPERATOR',  r'[\+\-\*/]'),    # Operators (+, -, *, /)
        ('SKIP',      r'[ \t]+'),       # Ignore spaces/tabs
        ('NEWLINE',   r'\n'),           # New lines
        ('MISMATCH',  r'.'),            # Any unknown character
    ]
    
    # Join all the regex patterns
    master_pattern = '|'.join(f'(?P<{pair[0]}>{pair[1]})' for pair in token_specification)
    
    # Scan the input code
    for match in re.finditer(master_pattern, code):
        kind = match.lastgroup
        value = match.group()
        
        if kind == 'SKIP' or kind == 'NEWLINE':
            continue  # Ignore spaces and new lines
        elif kind == 'MISMATCH':
            raise RuntimeError(f"Lexical Error: Unexpected character '{value}'")
        else:
            # For STRING tokens, remove the surrounding quotes
            if kind == 'STRING':
                value = value[1:-1]  # Remove the surrounding quotes (both single and double quotes)
            tokens.append((kind, value))
    
    return tokens
